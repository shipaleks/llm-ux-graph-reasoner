#!/usr/bin/env python3
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–æ–≤.
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ–º –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π –∏ —É–ª—É—á—à–µ–Ω–Ω—ã–π 
–º–µ—Ç–æ–¥ –Ω–∞ –±–∞–∑–µ Gemini 2.0 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –≤–∫–ª—é—á–∞—è
—Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ WEBVTT —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—ã.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    ./universal_analyzer.py <–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É> [--output <–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è>] [--mode <—Ä–µ–∂–∏–º>]
    
–†–µ–∂–∏–º—ã:
    standard - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ–º –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    gemini - –ø—Ä—è–º–æ–π –∞–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é Gemini 2.0
    combined - –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (—Å–Ω–∞—á–∞–ª–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π, –∑–∞—Ç–µ–º Gemini)
"""

import os
import sys
import json
import logging
import argparse
import time
import subprocess
import requests
import glob
from datetime import datetime
from pathlib import Path
import google.generativeai as genai
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini API
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    logger.error("API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª .env —Å–æ–¥–µ—Ä–∂–∏—Ç GOOGLE_API_KEY.")
    sys.exit(1)

genai.configure(api_key=GOOGLE_API_KEY)

def parse_arguments():
    """–†–∞–∑–±–æ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(
        description="–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–æ–≤"
    )
    
    parser.add_argument(
        "file_path",
        help="–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
    )
    
    parser.add_argument(
        "--output", "-o",
        default="output/universal",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: output/universal)"
    )
    
    parser.add_argument(
        "--mode", "-m",
        choices=["standard", "gemini", "combined"],
        default="combined",
        help="–†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞ (standard/gemini/combined, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: combined)"
    )
    
    parser.add_argument(
        "--max-segments", "-s",
        type=int,
        default=None,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"
    )
    
    return parser.parse_args()

def run_standard_analysis(file_path, output_dir, max_segments=None):
    """–ó–∞–ø—É—Å–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ–º –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π."""
    logger.info(f"–ó–∞–ø—É—Å–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è —Ñ–∞–π–ª–∞: {file_path}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—ã–≤–æ–¥–∞
    os.makedirs(output_dir, exist_ok=True)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —à–∞–Ω—Å–æ–≤ —É—Å–ø–µ—Ö–∞
    cmd = [
        "./analyze_text.py",
        file_path,
        "--provider", "gemini", 
        "--theories",               # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–æ—Ä–∏–π
        "--output", output_dir
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
    if max_segments:
        cmd.extend(["--max-segments", str(max_segments)])
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
    start_time = time.time()
    logger.info(f"–ó–∞–ø—É—Å–∫ –∫–æ–º–∞–Ω–¥—ã: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        elapsed_time = time.time() - start_time
        logger.info(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        # –ü–æ–∏—Å–∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º output_dir –¥–ª—è —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ timestamp (YYYYMMDD_HHMMSS)
        output_dirs = sorted(glob.glob(f"{output_dir}/[0-9]*_[0-9]*"), reverse=True)
        
        if output_dirs:
            output_dir = output_dirs[0]
            logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ—Ç—á–µ—Ç–æ–≤
            if os.path.exists(os.path.join(output_dir, "context")):
                logger.info("–ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
            else:
                logger.warning("–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                
            if os.path.exists(os.path.join(output_dir, "entities")):
                logger.info("–ù–∞–π–¥–µ–Ω—ã –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏")
            else:
                logger.warning("–°—É—â–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                
            if os.path.exists(os.path.join(output_dir, "relationships")):
                logger.info("–ù–∞–π–¥–µ–Ω—ã –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è")
            else:
                logger.warning("–û—Ç–Ω–æ—à–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                
            if os.path.exists(os.path.join(output_dir, "graphs")):
                logger.info("–ù–∞–π–¥–µ–Ω—ã –≥—Ä–∞—Ñ—ã –∑–Ω–∞–Ω–∏–π")
            else:
                logger.warning("–ì—Ä–∞—Ñ—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                
            if os.path.exists(os.path.join(output_dir, "theories")):
                logger.info("–ù–∞–π–¥–µ–Ω—ã —Ç–µ–æ—Ä–∏–∏")
            else:
                logger.warning("–¢–µ–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
            return output_dir, True, result.stdout
        else:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é")
            return None, False, result.stdout
    except subprocess.CalledProcessError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
        logger.error(f"Stdout: {e.stdout}")
        logger.error(f"Stderr: {e.stderr}")
        return None, False, e.stderr
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        return None, False, str(e)

def detect_language(text):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞."""
    sample = text[:10000]  # –ë–µ—Ä–µ–º —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    cyrillic_count = sum(1 for c in sample if '–∞' <= c.lower() <= '—è')
    total_chars = sum(1 for c in sample if c.isalpha())
    
    if total_chars == 0:
        return "en"
        
    cyrillic_ratio = cyrillic_count / total_chars
    return "ru" if cyrillic_ratio > 0.3 else "en"

def clean_webvtt(text):
    """–û—á–∏—Å—Ç–∫–∞ WEBVTT –æ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫."""
    lines = text.split('\n')
    cleaned_lines = []
    
    skip_next = False
    for line in lines:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ WEBVTT
        if line.startswith("WEBVTT"):
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        if not line.strip():
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
        if "-->" in line and any(c.isdigit() for c in line):
            skip_next = False
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫
        if line.strip().isdigit():
            skip_next = True
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥
        if skip_next:
            skip_next = False
            continue
            
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É –≤ –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        cleaned_lines.append(line)
    
    return "\n".join(cleaned_lines)

async def run_gemini_analysis(file_path, output_dir):
    """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Gemini 2.0."""
    logger.info(f"–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ Gemini 2.0 –¥–ª—è —Ñ–∞–π–ª–∞: {file_path}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    gemini_output_dir = os.path.join(output_dir, f"gemini_{timestamp}")
    os.makedirs(gemini_output_dir, exist_ok=True)
    
    # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return None, False
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∞
    language = detect_language(text)
    is_russian = language == "ru"
    is_webvtt = text.startswith("WEBVTT")
    
    logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω —è–∑—ã–∫: {'—Ä—É—Å—Å–∫–∏–π' if is_russian else '–∞–Ω–≥–ª–∏–π—Å–∫–∏–π'}")
    logger.info(f"–§–æ—Ä–º–∞—Ç WEBVTT: {'–¥–∞' if is_webvtt else '–Ω–µ—Ç'}")
    
    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ WEBVTT
    if is_webvtt:
        text = clean_webvtt(text)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Gemini 2.0
    model = genai.GenerativeModel('gemini-2.0-pro-exp-02-05')
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π
    logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π...")
    if is_russian:
        summary_prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏ —Å–¥–µ–ª–∞–π –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é. 
        –í–∫–ª—é—á–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–∑–∏—Å—ã –∏ 5-7 –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤.
        
        –¢–µ–∫—Å—Ç:
        {text[:50000]}  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è Gemini 2.0
        """
    else:
        summary_prompt = f"""
        Analyze the following text and provide a detailed summary. 
        Include a title, main points, and 5-7 key insights.
        
        Text:
        {text[:50000]}  # Increased context size for Gemini 2.0
        """
    
    try:
        response = model.generate_content(summary_prompt)
        summary_response = response.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Gemini: {e}")
        summary_response = "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏."
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–æ—Ä–∏–π
    logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–æ—Ä–∏–π...")
    if is_russian:
        theory_prompt = f"""
        –ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞, —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π 3-5 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–æ—Ä–∏–π –∏–ª–∏ –≥–∏–ø–æ—Ç–µ–∑.
        –î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–æ—Ä–∏–∏ —É–∫–∞–∂–∏:
        1. –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–æ—Ä–∏–∏
        2. –û–ø–∏—Å–∞–Ω–∏–µ (3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
        3. –°—Ç–µ–ø–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0-100%)
        4. 2-3 –≥–∏–ø–æ—Ç–µ–∑—ã, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∏–µ —Ç–µ–æ—Ä–∏—é
        5. 1-2 –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∏—Ö —Ñ–∞–∫—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –≥–∏–ø–æ—Ç–µ–∑—ã
        
        –ü—Ä–µ–¥—Å—Ç–∞–≤—å –æ—Ç–≤–µ—Ç –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
        
        –¢–µ–∫—Å—Ç:
        {text[:50000]}  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è Gemini 2.0
        """
    else:
        theory_prompt = f"""
        Based on the following text, formulate 3-5 main theories.
        For each theory, include:
        1. Theory name
        2. Description (3-5 sentences)
        3. Confidence level (0-100%)
        4. 2-3 hypotheses supporting the theory
        5. 1-2 supporting facts for each hypothesis
        
        Present your answer in a structured format.
        
        Text:
        {text[:50000]}  # Increased context size for Gemini 2.0
        """
    
    try:
        response = model.generate_content(theory_prompt)
        theory_response = response.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Gemini: {e}")
        theory_response = "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–æ—Ä–∏–π."
    
    # –°–æ–∑–¥–∞–Ω–∏–µ HTML-–æ—Ç—á–µ—Ç–∞
    if is_russian:
        title = "–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å Gemini 2.0"
        summary_title = "–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è"
        theory_title = "–¢–µ–æ—Ä–∏–∏ –∏ –≥–∏–ø–æ—Ç–µ–∑—ã"
        file_label = "–§–∞–π–ª"
        date_label = "–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"
    else:
        title = "Text Analysis with Gemini 2.0"
        summary_title = "Summary"
        theory_title = "Theories and Hypotheses"
        file_label = "File"
        date_label = "Analysis Date"
    
    html_content = f"""
    <!DOCTYPE html>
    <html lang="{language}">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{title}</title>
        <style>
            body {{
                font-family: Arial, sans-serif;
                line-height: 1.6;
                max-width: 1200px;
                margin: 0 auto;
                padding: 20px;
                color: #333;
            }}
            h1, h2 {{
                color: #2c3e50;
            }}
            .container {{
                background-color: #f5f9ff;
                border-left: 4px solid #4a90e2;
                margin-bottom: 20px;
                padding: 15px;
                border-radius: 4px;
            }}
            .metadata {{
                background-color: #f9f9f9;
                padding: 15px;
                border-left: 4px solid #2c3e50;
                margin-bottom: 20px;
            }}
            pre {{
                white-space: pre-wrap;
                background-color: #f8f8f8;
                padding: 10px;
                border-radius: 4px;
                line-height: 1.5;
            }}
        </style>
    </head>
    <body>
        <h1>{title}</h1>
        
        <div class="metadata">
            <p><strong>{file_label}:</strong> {os.path.basename(file_path)}</p>
            <p><strong>{date_label}:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>Model:</strong> Gemini 2.0</p>
        </div>
        
        <h2>{summary_title}</h2>
        <div class="container">
            <pre>{summary_response}</pre>
        </div>
        
        <h2>{theory_title}</h2>
        <div class="container">
            <pre>{theory_response}</pre>
        </div>
    </body>
    </html>
    """
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report_path = os.path.join(gemini_output_dir, "report.html")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    results = {
        "summary": summary_response,
        "theories": theory_response,
        "metadata": {
            "file": os.path.basename(file_path),
            "date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "language": language,
            "is_webvtt": is_webvtt,
            "model": "gemini-2.0-pro-exp-02-05"
        }
    }
    
    json_path = os.path.join(gemini_output_dir, "results.json")
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    logger.info(f"–ê–Ω–∞–ª–∏–∑ Gemini –∑–∞–≤–µ—Ä—à–µ–Ω, –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    return gemini_output_dir, True

def create_combined_report(standard_dir, gemini_dir, output_dir, file_path):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±–æ–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤."""
    if not standard_dir and not gemini_dir:
        logger.error("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
        return None
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    has_standard_graph = False
    has_standard_theories = False
    has_standard_context = False
    
    if standard_dir:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≥—Ä–∞—Ñ–æ–≤
        graph_dir = os.path.join(standard_dir, "graphs")
        has_standard_graph = os.path.exists(graph_dir) and any(f.endswith(".html") for f in os.listdir(graph_dir)) if os.path.exists(graph_dir) else False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–µ–æ—Ä–∏–π
        theories_dir = os.path.join(standard_dir, "theories")
        has_standard_theories = os.path.exists(theories_dir) and any(f.endswith(".md") for f in os.listdir(theories_dir)) if os.path.exists(theories_dir) else False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        context_dir = os.path.join(standard_dir, "context")
        summaries_file = os.path.join(context_dir, "segment_summaries.json")
        has_standard_context = os.path.exists(summaries_file)
        
        if has_standard_context:
            logger.info("–ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Gemini
    has_gemini_results = False
    gemini_context = {}
    
    if gemini_dir:
        json_path = os.path.join(gemini_dir, "results.json")
        if os.path.exists(json_path):
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    gemini_context = json.load(f)
                has_gemini_results = True
                logger.info("–ù–∞–π–¥–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ Gemini")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö Gemini: {e}")
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –∫–∞–∫–∏–µ-—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
    if not (has_standard_graph or has_standard_theories or has_standard_context or has_gemini_results):
        logger.error("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤ –æ—Ç—á–µ—Ç–µ")
        return None
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            text_sample = f.read(10000)
        language = detect_language(text_sample)
    except Exception:
        language = "en"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
    
    is_russian = language == "ru"
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —è–∑—ã–∫–∞
    if is_russian:
        title = "–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"
        standard_title = "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π)"
        gemini_title = "–ê–Ω–∞–ª–∏–∑ Gemini 2.0"
        summary_title = "–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è"
        theory_title = "–¢–µ–æ—Ä–∏–∏ –∏ –≥–∏–ø–æ—Ç–µ–∑—ã"
        graph_title = "–ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π"
        file_label = "–§–∞–π–ª"
        date_label = "–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"
        no_data = "–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç"
    else:
        title = "Comprehensive Text Analysis"
        standard_title = "Standard Analysis (Knowledge Graph)"
        gemini_title = "Gemini 2.0 Analysis"
        summary_title = "Summary"
        theory_title = "Theories and Hypotheses"
        graph_title = "Knowledge Graph"
        file_label = "File"
        date_label = "Analysis Date"
        no_data = "No data available"
    
    # –ü–æ–∏—Å–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    standard_graph_path = None
    standard_theories_path = None
    
    if standard_dir and os.path.exists(standard_dir):
        graph_dir = os.path.join(standard_dir, "graphs")
        theories_dir = os.path.join(standard_dir, "theories")
        
        if os.path.exists(graph_dir):
            graph_files = [f for f in os.listdir(graph_dir) if f.endswith(".html")]
            if graph_files:
                standard_graph_path = os.path.join(graph_dir, graph_files[0])
        
        if os.path.exists(theories_dir):
            theory_files = [f for f in os.listdir(theories_dir) if f.endswith(".md")]
            if theory_files:
                standard_theories_path = os.path.join(theories_dir, theory_files[0])
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Gemini-–∞–Ω–∞–ª–∏–∑–∞
    gemini_summary = no_data
    gemini_theories = no_data
    
    if gemini_dir and os.path.exists(gemini_dir):
        json_path = os.path.join(gemini_dir, "results.json")
        if os.path.exists(json_path):
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    results = json.load(f)
                    gemini_summary = results.get("summary", no_data)
                    gemini_theories = results.get("theories", no_data)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö Gemini: {e}")
    
    # –ß—Ç–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Ç–µ–æ—Ä–∏–π
    standard_theories = no_data
    if standard_theories_path and os.path.exists(standard_theories_path):
        try:
            with open(standard_theories_path, 'r', encoding='utf-8') as f:
                standard_theories = f.read()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Ç–µ–æ—Ä–∏–π: {e}")
            
    # –ß—Ç–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞, –µ—Å–ª–∏ —Ç–µ–æ—Ä–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã
    context_summaries = {}
    if has_standard_context and standard_theories == no_data:
        context_file = os.path.join(standard_dir, "context", "segment_summaries.json")
        try:
            with open(context_file, 'r', encoding='utf-8') as f:
                context_summaries = json.load(f)
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(context_summaries)} —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –Ω–æ –Ω–µ—Ç —Ç–µ–æ—Ä–∏–π, —Å–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π
                if context_summaries and standard_theories == no_data:
                    context_text = []
                    for segment_id, summary in context_summaries.items():
                        if "title" in summary and "summary" in summary:
                            context_text.append(f"## {summary['title']}\n\n{summary['summary']}\n")
                            if "key_points" in summary and summary["key_points"]:
                                context_text.append("### –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:\n")
                                for point in summary["key_points"]:
                                    context_text.append(f"- {point}\n")
                                context_text.append("\n")
                    
                    if context_text:
                        standard_theories = "# –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n\n" + "\n".join(context_text)
                        logger.info("–°–æ–∑–¥–∞–Ω–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π –¥–ª—è –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è
    standard_graph_embed = ""
    if standard_graph_path:
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        rel_path = os.path.relpath(standard_graph_path, output_dir)
        standard_graph_embed = f"""
        <div class="iframe-container">
            <iframe src="{rel_path}" width="100%" height="600px" frameborder="0"></iframe>
        </div>
        """
    else:
        standard_graph_embed = f"<p>{no_data}</p>"
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    combined_dir = os.path.join(output_dir, f"combined_{timestamp}")
    os.makedirs(combined_dir, exist_ok=True)
    
    html_content = f"""
    <!DOCTYPE html>
    <html lang="{language}">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{title}</title>
        <style>
            body {{
                font-family: Arial, sans-serif;
                line-height: 1.6;
                max-width: 1200px;
                margin: 0 auto;
                padding: 20px;
                color: #333;
            }}
            h1, h2, h3 {{
                color: #2c3e50;
            }}
            .container {{
                background-color: #f5f9ff;
                border-left: 4px solid #4a90e2;
                margin-bottom: 20px;
                padding: 15px;
                border-radius: 4px;
            }}
            .metadata {{
                background-color: #f9f9f9;
                padding: 15px;
                border-left: 4px solid #2c3e50;
                margin-bottom: 20px;
            }}
            pre {{
                white-space: pre-wrap;
                background-color: #f8f8f8;
                padding: 10px;
                border-radius: 4px;
                line-height: 1.5;
                font-size: 14px;
            }}
            .section {{
                margin-bottom: 30px;
                border-bottom: 1px solid #eee;
                padding-bottom: 20px;
            }}
            .iframe-container {{
                width: 100%;
                margin: 20px 0;
            }}
            .side-by-side {{
                display: flex;
                flex-wrap: wrap;
                gap: 20px;
            }}
            .side-by-side > div {{
                flex: 1;
                min-width: 300px;
            }}
            .comparison-header {{
                background-color: #e8f4fc;
                padding: 10px;
                border-radius: 4px;
                margin-bottom: 15px;
                text-align: center;
            }}
        </style>
    </head>
    <body>
        <h1>{title}</h1>
        
        <div class="metadata">
            <p><strong>{file_label}:</strong> {os.path.basename(file_path)}</p>
            <p><strong>{date_label}:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="section">
            <h2>{gemini_title} - {summary_title}</h2>
            <div class="container">
                <pre>{gemini_summary}</pre>
            </div>
        </div>
        
        <div class="section">
            <h2>{theory_title}</h2>
            
            <div class="side-by-side">
                <div>
                    <div class="comparison-header">{standard_title}</div>
                    <div class="container">
                        <pre>{standard_theories}</pre>
                    </div>
                </div>
                
                <div>
                    <div class="comparison-header">{gemini_title}</div>
                    <div class="container">
                        <pre>{gemini_theories}</pre>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="section">
            <h2>{graph_title}</h2>
            {standard_graph_embed}
        </div>
    </body>
    </html>
    """
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report_path = os.path.join(combined_dir, "combined_report.html")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    logger.info(f"–°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç: {report_path}")
    return report_path

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    args = parse_arguments()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    if not os.path.exists(args.file_path):
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.file_path}")
        return 1
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(args.output, timestamp)
    os.makedirs(output_dir, exist_ok=True)
    
    standard_dir = None
    gemini_dir = None
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    if args.mode in ["standard", "combined"]:
        logger.info("–ó–∞–ø—É—Å–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
        standard_dir, standard_success, _ = run_standard_analysis(
            args.file_path, 
            os.path.join(output_dir, "standard"),
            args.max_segments
        )
    
    if args.mode in ["gemini", "combined"]:
        logger.info("–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å Gemini 2.0...")
        import asyncio
        gemini_dir, gemini_success = await run_gemini_analysis(
            args.file_path, 
            output_dir
        )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    if args.mode == "combined":
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ Gemini
        has_standard_results = False
        if standard_dir:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥—Ä–∞—Ñ–æ–≤ –∏–ª–∏ —Ç–µ–æ—Ä–∏–π
            has_context = os.path.exists(os.path.join(standard_dir, "context"))
            has_graphs = os.path.exists(os.path.join(standard_dir, "graphs"))
            has_theories = os.path.exists(os.path.join(standard_dir, "theories"))
            has_standard_results = has_context or has_graphs or has_theories
            
            if not (has_graphs or has_theories):
                logger.warning("–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ —Å–æ–∑–¥–∞–ª –≥—Ä–∞—Ñ—ã –∏–ª–∏ —Ç–µ–æ—Ä–∏–∏")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —Å–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        if gemini_dir or (standard_dir and has_standard_results):
            logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
            combined_report = create_combined_report(
                standard_dir, 
                gemini_dir, 
                output_dir, 
                args.file_path
            )
            
            if combined_report:
                logger.info(f"–ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                print(f"\n‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                print(f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {combined_report}")
                print("üåê –í—ã –º–æ–∂–µ—Ç–µ –æ—Ç–∫—Ä—ã—Ç—å –µ–≥–æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ.")
                return 0
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞, –Ω–æ –µ—Å—Ç—å Gemini
        if gemini_dir:
            print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
            if standard_dir:
                print(f"‚ö†Ô∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ –Ω–µ —Å–æ–∑–¥–∞–ª –≥—Ä–∞—Ñ—ã –∏–ª–∏ —Ç–µ–æ—Ä–∏–∏")
                print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ—Å—Ç—É–ø–Ω—ã –≤: {standard_dir}")
            print(f"üìä –û—Ç—á–µ—Ç Gemini 2.0 —Å–æ–∑–¥–∞–Ω: {os.path.join(gemini_dir, 'report.html')}")
            print("üåê –í—ã –º–æ–∂–µ—Ç–µ –æ—Ç–∫—Ä—ã—Ç—å –µ–≥–æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ.")
            return 0
    elif args.mode == "standard" and standard_dir:
        # –ù–∞—Ö–æ–¥–∏–º –ª—é–±—ã–µ –æ—Ç—á–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω—ã
        reports = []
        if os.path.exists(os.path.join(standard_dir, "graphs")):
            graph_files = [os.path.join(standard_dir, "graphs", f) 
                         for f in os.listdir(os.path.join(standard_dir, "graphs")) 
                         if f.endswith(".html")]
            reports.extend(graph_files)
        
        if os.path.exists(os.path.join(standard_dir, "theories")):
            theory_files = [os.path.join(standard_dir, "theories", f) 
                          for f in os.listdir(os.path.join(standard_dir, "theories")) 
                          if f.endswith(".md") or f.endswith(".html")]
            reports.extend(theory_files)
        
        print(f"\n‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {standard_dir}")
        
        if reports:
            print("üìÑ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã:")
            for report in reports:
                print(f"   - {report}")
        else:
            print("‚ö†Ô∏è –û—Ç—á–µ—Ç—ã –Ω–µ –±—ã–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã. –î–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑.")
            ctx_file = os.path.join(standard_dir, "context", "segment_summaries.json")
            if os.path.exists(ctx_file):
                print(f"üìä –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {ctx_file}")
    elif args.mode == "gemini" and gemini_dir:
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ Gemini 2.0 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìä –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {os.path.join(gemini_dir, 'report.html')}")
        print("üåê –í—ã –º–æ–∂–µ—Ç–µ –æ—Ç–∫—Ä—ã—Ç—å –µ–≥–æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ.")
    
    return 0

if __name__ == "__main__":
    import asyncio
    sys.exit(asyncio.run(main()))