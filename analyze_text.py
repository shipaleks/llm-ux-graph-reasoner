#!/usr/bin/env python3
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞.
–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π, –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    ./analyze_text.py <–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É> [--provider <–ø—Ä–æ–≤–∞–π–¥–µ—Ä>] [--expand] [--theories]

–ü—Ä–∏–º–µ—Ä—ã:
    ./analyze_text.py test_synthetic_text.txt
    ./analyze_text.py docs/sample.txt --provider gemini --expand
"""

import os
import sys
import argparse
import logging
import time
import json
import re
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
log_formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
log_file = f"{os.path.basename(__file__)}.log"

# –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
file_handler = logging.FileHandler(log_file, mode='w')
file_handler.setFormatter(log_formatter)
file_handler.setLevel(logging.DEBUG)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å DEBUG –¥–ª—è —Ñ–∞–π–ª–∞

# –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
console_handler = logging.StreamHandler()
console_handler.setFormatter(log_formatter)
console_handler.setLevel(logging.INFO)  # –û—Å—Ç–∞–≤–ª—è–µ–º INFO –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä
logging.basicConfig(
    level=logging.DEBUG,  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º DEBUG –¥–ª—è –∫–æ—Ä–Ω–µ–≤–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞
    handlers=[file_handler, console_handler]
)

logger = logging.getLogger(__name__)

# –î–æ–±–∞–≤–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
src_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "src")
sys.path.insert(0, src_dir)

# –¢–µ–ø–µ—Ä—å –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –ø–∞–∫–µ—Ç–∞ knowledge_graph_synth
from knowledge_graph_synth.cli.commands import main

def parse_arguments():
    """–†–∞–∑–±–æ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(
        description="–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π"
    )
    
    parser.add_argument(
        "file_path",
        help="–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
    )
    
    parser.add_argument(
        "--provider", "-p",
        default="gemini",
        choices=["gemini", "openai"],
        help="–ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: gemini)"
    )
    
    parser.add_argument(
        "--expand", "-e",
        action="store_true",
        help="–†–∞—Å—à–∏—Ä–∏—Ç—å –≥—Ä–∞—Ñ —á–µ—Ä–µ–∑ –∑–∞–¥–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤"
    )
    
    parser.add_argument(
        "--theories", "-t",
        action="store_true",
        help="–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–æ—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—Ä–∞—Ñ–∞"
    )
    
    parser.add_argument(
        "--no-segments", "-n",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"
    )
    
    parser.add_argument(
        "--output", "-o",
        default="output",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: output)"
    )
    
    parser.add_argument(
        "--max-segments", "-m",
        type=int,
        default=None,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"
    )
    
    return parser.parse_args()

def run_analysis(args):
    """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
    start_time = time.time()
    logger.info(f"–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞: {args.file_path}")
    
    if not os.path.exists(args.file_path):
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.file_path}")
        return 1
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤—ã–≤–æ–¥–∞
    if not os.path.exists(args.output):
        try:
            os.makedirs(args.output)
            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –≤—ã–≤–æ–¥–∞: {args.output}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤—ã–≤–æ–¥–∞: {str(e)}")
            return 1
    
    # –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    cmd_args = [
        "process",
        "-f", args.file_path,
        "-e",  # –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π
        "-b",  # –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞
        "--provider", args.provider,
        "--generate-report",  # –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        "--output", args.output
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–µ–≥–º–µ–Ω—Ç–æ–≤, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
    if args.max_segments:
        cmd_args.extend(["--max-segments", str(args.max_segments)])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    if not args.no_segments:
        cmd_args.append("--contextual-analysis")
    
    if args.expand:
        cmd_args.append("--expand-graph")
    
    if args.theories:
        cmd_args.append("-g")  # –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–æ—Ä–∏–π
    
    # –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∞–Ω–∞–ª–∏–∑–∞
    logger.info(f"–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: {' '.join(cmd_args)}")
    
    try:
        result = main(cmd_args)
        
        # –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω, —Å–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        if result == 0:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–æ–∑–¥–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            import glob
            
            # –ù–∞–π—Ç–∏ —Å–∞–º—É—é –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –æ—Ç–º–µ—Ç–∫–æ–π –≤—Ä–µ–º–µ–Ω–∏
            output_dirs = sorted(glob.glob(f"{args.output}/[0-9]*_[0-9]*"), reverse=True)
            
            if output_dirs:
                latest_dir = output_dirs[0]
                logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è {latest_dir}")
                
                try:
                    # Call improve_report_en.py for English report
                    improve_cmd = ["./improve_report_en.py", "--dir", latest_dir, "--force"]
                    logger.info(f"Running English report improvement with command: {' '.join(improve_cmd)}")
                    
                    improve_result = subprocess.run(improve_cmd, capture_output=True, text=True)
                    
                    if improve_result.returncode != 0:
                        logger.warning(f"Warning when improving report: {improve_result.stderr}")
                        logger.info(f"Standard report available at: {latest_dir}")
                        print(f"\n‚ö†Ô∏è Warning when creating improved English report.")
                        print(f"üìä Standard report available at: {latest_dir}")
                    else:
                        # Find the path to the improved report in the output
                        improved_report_path = None
                        for line in improve_result.stdout.split('\n'):
                            if "successfully improved:" in line or "Report successfully improved:" in line:
                                improved_report_path = line.split(":")[-1].strip()
                                break
                        
                        if improved_report_path and os.path.exists(improved_report_path):
                            logger.info(f"Improved English report created: {improved_report_path}")
                            print(f"\n‚úÖ Improved English report created: {improved_report_path}")
                            print("üåê You can open it in your browser.")
                        else:
                            print(f"\n‚ö†Ô∏è Analysis completed, but the improved English report may not have been created.")
                            print(f"üìä Standard report available at: {latest_dir}")
                except Exception as report_error:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {str(report_error)}")
        
        # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–≥–æ–≤
        try:
            # –ù–∞–π—Ç–∏ —Å–∞–º—É—é –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –æ—Ç–º–µ—Ç–∫–æ–π –≤—Ä–µ–º–µ–Ω–∏
            import glob
            output_dirs = sorted(glob.glob(f"{args.output}/[0-9]*_[0-9]*"), reverse=True)
            
            if output_dirs:
                latest_dir = output_dirs[0]
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–∫–µ–Ω–∞—Ö
                api_calls = 0
                input_tokens = 0
                output_tokens = 0
                calls_by_model = {}
                tokens_by_model = {}
                duration_total = 0.0
                
                # –ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –ª–æ–≥—É
                log_pattern = re.compile(r'API call to ([^:]+): (\d+) input tokens, (\d+) output tokens, ([0-9.]+)s')
                
                log_files = [log_file]  # –ù–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—à–µ–≥–æ –ª–æ–≥-—Ñ–∞–π–ª–∞
                
                # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ª–æ–≥–æ–≤
                for log_f in log_files:
                    if os.path.exists(log_f):
                        logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥-—Ñ–∞–π–ª: {log_f}")
                        with open(log_f, "r", encoding="utf-8", errors="ignore") as f:
                            content = f.read()
                            logger.info(f"–†–∞–∑–º–µ—Ä –ª–æ–≥-—Ñ–∞–π–ª–∞: {len(content)} –±–∞–π—Ç")
                            
                            # –ò—â–µ–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                            for match in log_pattern.finditer(content):
                                model = match.group(1)
                                in_tokens = int(match.group(2))
                                out_tokens = int(match.group(3))
                                duration = float(match.group(4))
                                
                                logger.info(f"–ù–∞–π–¥–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ API: {model}, {in_tokens} –≤—Ö. —Ç–æ–∫–µ–Ω–æ–≤, {out_tokens} –≤—ã—Ö. —Ç–æ–∫–µ–Ω–æ–≤")
                                
                                api_calls += 1
                                input_tokens += in_tokens
                                output_tokens += out_tokens
                                duration_total += duration
                                
                                if model not in calls_by_model:
                                    calls_by_model[model] = 0
                                    tokens_by_model[model] = {"input": 0, "output": 0}
                                
                                calls_by_model[model] += 1
                                tokens_by_model[model]["input"] += in_tokens
                                tokens_by_model[model]["output"] += out_tokens
                
                # –ï—Å–ª–∏ –ª–æ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –≤ –≤—ã–≤–æ–¥–µ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
                if api_calls == 0:
                    # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—ã–≤–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
                    log_output = os.popen(f"grep 'API call to' -r {latest_dir}/").read()
                    for line in log_output.split("\n"):
                        match = log_pattern.search(line)
                        if match:
                            model = match.group(1)
                            in_tokens = int(match.group(2))
                            out_tokens = int(match.group(3))
                            duration = float(match.group(4))
                            
                            api_calls += 1
                            input_tokens += in_tokens
                            output_tokens += out_tokens
                            duration_total += duration
                            
                            if model not in calls_by_model:
                                calls_by_model[model] = 0
                                tokens_by_model[model] = {"input": 0, "output": 0}
                            
                            calls_by_model[model] += 1
                            tokens_by_model[model]["input"] += in_tokens
                            tokens_by_model[model]["output"] += out_tokens
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                total_cost = 0.0
                model_costs = {}
                
                # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ü–µ–Ω—ã –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤
                cost_per_1k = {
                    "gemini-2.0-flash": {"input": 0.000125, "output": 0.000375},  # $0.125/1M input, $0.375/1M output
                    "gemini-2.0-pro-exp-02-05": {"input": 0.0005, "output": 0.0015},  # $0.5/1M input, $1.5/1M output
                    "default_gemini": {"input": 0.0005, "output": 0.0015},
                    "default_openai": {"input": 0.001, "output": 0.002},
                }
                
                for model, tokens in tokens_by_model.items():
                    # Get cost rates for this model
                    if model in cost_per_1k:
                        rates = cost_per_1k[model]
                    elif "gemini" in model.lower():
                        rates = cost_per_1k["default_gemini"]
                    else:
                        rates = cost_per_1k["default_openai"]
                    
                    # Calculate costs
                    input_cost = (tokens["input"] / 1000) * rates["input"]
                    output_cost = (tokens["output"] / 1000) * rates["output"]
                    model_cost = input_cost + output_cost
                    
                    model_costs[model] = {
                        "input_tokens": tokens["input"],
                        "output_tokens": tokens["output"],
                        "input_cost": input_cost,
                        "output_cost": output_cost,
                        "total_cost": model_cost
                    }
                    
                    total_cost += model_cost
                
                # –°–æ–∑–¥–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç
                summary = [
                    "Token Usage Summary",
                    "==================="
                ]
                
                # Add general stats
                summary.extend([
                    f"Total API Calls: {api_calls}",
                    f"Total Tokens: {input_tokens + output_tokens} (Input: {input_tokens}, Output: {output_tokens})",
                    f"Estimated Cost: ${total_cost:.6f} USD",
                    f"Total API Duration: {duration_total:.2f} seconds",
                    f"Total Analysis Time: {time.time() - start_time:.2f} seconds",
                    "",
                    "Model Breakdown:",
                ])
                
                # Add per-model stats
                for model, cost_info in model_costs.items():
                    summary.extend([
                        f"  {model}:",
                        f"    Calls: {calls_by_model[model]}",
                        f"    Tokens: {cost_info['input_tokens'] + cost_info['output_tokens']} (Input: {cost_info['input_tokens']}, Output: {cost_info['output_tokens']})",
                        f"    Cost: ${cost_info['total_cost']:.6f} USD",
                        ""
                    ])
                
                token_stats = "\n".join(summary)
                print("\n" + token_stats)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ —Ñ–∞–π–ª –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                stats_path = os.path.join(latest_dir, "token_usage.txt")
                with open(stats_path, "w", encoding="utf-8") as f:
                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ –∏ –≤—Ä–µ–º–µ–Ω–∏ –∞–Ω–∞–ª–∏–∑–∞
                    f.write(f"File: {args.file_path}\n")
                    f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"Total analysis time: {time.time() - start_time:.2f} seconds\n\n")
                    f.write(token_stats)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–∫–∂–µ JSON-–¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    f.write("\n\nJSON DATA:\n")
                    json_data = {
                        "file": args.file_path,
                        "date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        "analysis_time": time.time() - start_time,
                        "api_calls": api_calls,
                        "input_tokens": input_tokens,
                        "output_tokens": output_tokens,
                        "total_tokens": input_tokens + output_tokens,
                        "total_cost_usd": total_cost,
                        "api_duration": duration_total,
                        "models": {
                            model: {
                                "calls": calls_by_model[model],
                                "input_tokens": info["input_tokens"],
                                "output_tokens": info["output_tokens"],
                                "input_cost": info["input_cost"],
                                "output_cost": info["output_cost"],
                                "total_cost": info["total_cost"]
                            } for model, info in model_costs.items()
                        }
                    }
                    f.write(json.dumps(json_data, indent=2))
                
                print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {stats_path}")
        except Exception as stats_error:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤: {str(stats_error)}")
        
        return result
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
        return 1

if __name__ == "__main__":
    args = parse_arguments()
    sys.exit(run_analysis(args))